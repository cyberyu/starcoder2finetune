{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3ee0906-3041-4a73-856b-ddc86006763c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd3b748ba39942229eb4c177b535fed8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "block_completion_v2.jsonl.gz:   0%|          | 0.00/3.21M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ab6415e902f405b9c793df9e234fc2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/4571 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"gonglinyuan/safim\", \"block_v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf8793d3-0232-4cb1-b5cb-3767a90cb3a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['lang', 'prompt', 'eval_prompt', 'ground_truth', 'unit_tests', 'task_id', 'problem_source'],\n",
       "        num_rows: 4571\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c27dad6-813a-4d04-8968-99b4fec36578",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DatasetDict' object has no attribute 'to_json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_json\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_data.jsonl\u001b[39m\u001b[38;5;124m\"\u001b[39m, lines\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DatasetDict' object has no attribute 'to_json'"
     ]
    }
   ],
   "source": [
    "ds.to_json(\"train_data.jsonl\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b5ccd36-5e6f-4806-b205-750c7c250483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a889d5748604480dbe26be3a0d00203d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/5 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "27431990"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = ds[\"test\"]\n",
    "\n",
    "# Dump to JSONL\n",
    "test_dataset.to_json(\"test_split.jsonl\", orient=\"records\", lines=True, force_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4110db4c-ee02-4dff-9588-47ef08a19c26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef9e4081ff4347cea78a935786cf425f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71f3c04a-fa73-4ccf-8ca7-cc7a2873572d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "ds_smol = load_dataset(\"bigcode/the-stack-smol\", data_dir=\"data/python\", token=)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be3ab245-640f-4a70-8ea8-44a9238189ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': '# Copyright 2020 gRPC authors.\\n#\\n# Licensed under the Apache License, Version 2.0 (the \"License\");\\n# you may not use this file except in compliance with the License.\\n# You may obtain a copy of the License at\\n#\\n#     http://www.apache.org/licenses/LICENSE-2.0\\n#\\n# Unless required by applicable law or agreed to in writing, software\\n# distributed under the License is distributed on an \"AS IS\" BASIS,\\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\\n# See the License for the specific language governing permissions and\\n# limitations under the License.\\n\"\"\"The Python AsyncIO implementation of the GRPC helloworld.Greeter server.\"\"\"\\n\\nimport logging\\nimport asyncio\\nimport grpc\\n\\nimport helloworld_pb2\\nimport helloworld_pb2_grpc\\n\\n\\nclass Greeter(helloworld_pb2_grpc.GreeterServicer):\\n\\n    async def SayHello(\\n            self, request: helloworld_pb2.HelloRequest,\\n            context: grpc.aio.ServicerContext) -> helloworld_pb2.HelloReply:\\n        return helloworld_pb2.HelloReply(message=\\'Hello, %s!\\' % request.name)\\n\\n\\nasync def serve() -> None:\\n    server = grpc.aio.server()\\n    helloworld_pb2_grpc.add_GreeterServicer_to_server(Greeter(), server)\\n    listen_addr = \\'[::]:50051\\'\\n    server.add_insecure_port(listen_addr)\\n    logging.info(\"Starting server on %s\", listen_addr)\\n    await server.start()\\n    try:\\n        await server.wait_for_termination()\\n    except KeyboardInterrupt:\\n        # Shuts down the server with 0 seconds of grace period. During the\\n        # grace period, the server won\\'t accept new connections and allow\\n        # existing RPCs to continue within the grace period.\\n        await server.stop(0)\\n\\n\\nif __name__ == \\'__main__\\':\\n    logging.basicConfig(level=logging.INFO)\\n    asyncio.run(serve())\\n',\n",
       " 'avg_line_length': 34.2156862745,\n",
       " 'max_line_length': 78,\n",
       " 'alphanum_fraction': 0.7318051576,\n",
       " 'licenses': ['Apache-2.0'],\n",
       " 'repository_name': '1261385937/grpc',\n",
       " 'path': 'examples/python/helloworld/async_greeter_server.py',\n",
       " 'size': 1745,\n",
       " 'lang': 'Python'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_smol[\"train\"].__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36a26a5d-3b41-48e5-804a-2035e05453ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30d65d14d93c4bed8903a944bab0ccee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "86617823"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_smol[\"train\"].to_json(\"train_split_python_stack_smol.jsonl\", orient=\"records\", lines=True, force_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7fd482ce-981a-406d-80b5-4b93f8fca772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3951e17a079e4ed0a00a6b0c3e3c6e0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/51 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "271650476"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "load_dataset(\"bigcode/self-oss-instruct-sc2-exec-filter-50k\", split=\"train\").to_json(\"oss_instruct_train_data.jsonl\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50ba8bd9-b7c4-4f5b-9d20-b370cca4c46e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25cf2a59a3354667a714e0e04f705019",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['content'],\n",
       "        num_rows: 6111219\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "issues_dataset = load_dataset(\"json\", data_files=\"nextline_fim.jsonl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c4bd751-fd4a-43e2-ae25-afd6cc368b0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['content'],\n",
       "    num_rows: 6111219\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issues_dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d20c142e-e91a-4b35-97a3-22f3ed5e67ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5f4d50c34504adbb436fd6036e50205",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/4 shards):   0%|          | 0/4935517 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61da67d4d20d41239a7991724dcc0bd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/548391 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved HuggingFace dataset to tbricksnext2lines/tbricks with 4935517 train and 548391 test samples.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from datasets import Dataset, DatasetDict\n",
    "import random\n",
    "\n",
    "# Load the FIM-formatted data\n",
    "input_path = \"nextline_fim_ver2.jsonl\"\n",
    "with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = [json.loads(line) for line in f if line.strip()]\n",
    "\n",
    "# Shuffle data for random split\n",
    "random.seed(42)\n",
    "random.shuffle(data)\n",
    "\n",
    "# Split 90% train, 10% test\n",
    "split_idx = int(0.9 * len(data))\n",
    "train_data = data[:split_idx]\n",
    "test_data = data[split_idx:]\n",
    "\n",
    "# Ensure all are dicts with 'content'\n",
    "train_data = [{'content': d['content']} for d in train_data if isinstance(d, dict) and 'content' in d]\n",
    "test_data = [{'content': d['content']} for d in test_data if isinstance(d, dict) and 'content' in d]\n",
    "\n",
    "\n",
    "# Create HuggingFace datasets\n",
    "train_dataset = Dataset.from_list(train_data)\n",
    "test_dataset = Dataset.from_list(test_data)\n",
    "dataset_dict = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"test\": test_dataset\n",
    "})\n",
    "\n",
    "# Save to disk in HuggingFace format under subset 'tbricks'\n",
    "dataset_dict.save_to_disk(\"tbricksnext2linesver2/tbricks\")\n",
    "print(f\"Saved HuggingFace dataset to tbricksnext2lines/tbricks with {len(train_data)} train and {len(test_data)} test samples.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd384445-0e85-43ed-80ae-72554cb48931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d8ac0fc08574a33ad54db6f868c9e1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds_smol.save_to_disk(\"bigcode/the-stack-smol\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ccc4d25-d8ad-4c0f-a77c-4a6c4c181de9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5047a611c0024ba2a8c889c0291d59c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/549 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c17f8fd340349c485474d9541a24b93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/4936 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1747715084"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import datasets\n",
    "\n",
    "ds2 = datasets.load_from_disk(\"tbricksnext2linesver2/tbricks\")\n",
    "#ds2 = datasets.load_from_disk(\"tbricksnext2linesver3/tbricks\")\n",
    "ds2[\"test\"].to_json(\"tbricksnext2lines_test.jsonl\", lines=True)\n",
    "ds2[\"train\"].to_json(\"tbricksnext2lines_train.jsonl\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f5442d0-d8dc-4d49-beba-c94f26bf6790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3323c0c86ef3470ba89b1e6b0c3b3316",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/4 shards):   0%|          | 0/4956037 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cee43c6d03c6444a8a41f774e5ccb6c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/550671 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved HuggingFace dataset to tbricksnext2lines/tbricks with 4956037 train and 550671 test samples.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from datasets import Dataset, DatasetDict\n",
    "import random\n",
    "\n",
    "# Load the FIM-formatted data\n",
    "input_path = \"combined_training_data.jsonl\"\n",
    "with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = [json.loads(line) for line in f if line.strip()]\n",
    "\n",
    "# Shuffle data for random split\n",
    "random.seed(42)\n",
    "random.shuffle(data)\n",
    "\n",
    "# Split 90% train, 10% test\n",
    "split_idx = int(0.9 * len(data))\n",
    "train_data = data[:split_idx]\n",
    "test_data = data[split_idx:]\n",
    "\n",
    "# Ensure all are dicts with 'content'\n",
    "train_data = [{'content': d['content']} for d in train_data if isinstance(d, dict) and 'content' in d]\n",
    "test_data = [{'content': d['content']} for d in test_data if isinstance(d, dict) and 'content' in d]\n",
    "\n",
    "\n",
    "# Create HuggingFace datasets\n",
    "train_dataset = Dataset.from_list(train_data)\n",
    "test_dataset = Dataset.from_list(test_data)\n",
    "dataset_dict = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"test\": test_dataset\n",
    "})\n",
    "\n",
    "# Save to disk in HuggingFace format under subset 'tbricks'\n",
    "dataset_dict.save_to_disk(\"tbricksnext2linesver3/tbricks\")\n",
    "print(f\"Saved HuggingFace dataset to tbricksnext2lines/tbricks with {len(train_data)} train and {len(test_data)} test samples.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e634eb4-3701-496e-a2ca-6de80f8a75cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18a156ce53624afeb3715870f97e9e6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/19012 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d2c1e11792b407f9d5714a7281a809f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/2113 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved HuggingFace dataset to tbricksnext2lines/tbricks with 19012 train and 2113 test samples.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from datasets import Dataset, DatasetDict\n",
    "import random\n",
    "\n",
    "# Load the FIM-formatted data\n",
    "input_path = \"prompts_transformed_filtered_ver2.jsonl\"\n",
    "with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = [json.loads(line) for line in f if line.strip()]\n",
    "\n",
    "# Shuffle data for random split\n",
    "random.seed(42)\n",
    "random.shuffle(data)\n",
    "\n",
    "# Split 90% train, 10% test\n",
    "split_idx = int(0.9 * len(data))\n",
    "train_data = data[:split_idx]\n",
    "test_data = data[split_idx:]\n",
    "\n",
    "# Ensure all are dicts with 'content'\n",
    "train_data = [{'content': d['content']} for d in train_data if isinstance(d, dict) and 'content' in d]\n",
    "test_data = [{'content': d['content']} for d in test_data if isinstance(d, dict) and 'content' in d]\n",
    "\n",
    "\n",
    "# Create HuggingFace datasets\n",
    "train_dataset = Dataset.from_list(train_data)\n",
    "test_dataset = Dataset.from_list(test_data)\n",
    "dataset_dict = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"test\": test_dataset\n",
    "})\n",
    "\n",
    "# Save to disk in HuggingFace format under subset 'tbricks'\n",
    "dataset_dict.save_to_disk(\"tbricksnext2linesver5/tbricks\")\n",
    "print(f\"Saved HuggingFace dataset to tbricksnext2lines/tbricks with {len(train_data)} train and {len(test_data)} test samples.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9bd85df-92f2-40ff-ad18-21d9d92bdfa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b671165d8fcf4add95360cd1d247bf05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb9642ae04d44f5fb2f8de2ebcc1f5fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/20 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "35243188"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datasets\n",
    "ds2 = datasets.load_from_disk(\"tbricksnext2linesver5/tbricks\")\n",
    "#ds2 = datasets.load_from_disk(\"tbricksnext2linesver3/tbricks\")\n",
    "ds2[\"test\"].to_json(\"prompt_nosuffix_test.jsonl\", lines=True)\n",
    "ds2[\"train\"].to_json(\"prompt_nosuffix_train.jsonl\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "728de7d5-bcc6-4516-b311-41e42afeeee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2280"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds2[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45d1e492-f256-46fa-8d7b-bbc3bd44ff24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20520"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds2[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d715a748-787d-41ae-b4df-4e48e368d221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': '<fim-prefix>#include <shared/volatility/VolatilityModelTypeMismatchException.h> #include <shared/volatility/ClampedCubicSpline.h> #include <shared/volatility/StochasticVolatilityInspired.h> #include <shared/volatility/WingVolatilityModel.h> SUPPRESS_SF_API_CLANG_WARNINGS #include <shared/sdk_definitions.h> CLANG_RESTORE_WARNINGS // Declare the generic cast functions but don\\'t implement them to cause compilation error on attempt to use them with unsupported volatility model types template <class ModelTypePtr> ModelTypePtr vol_model_cast(volatility::IVolatilityModel * pModel); template <class ModelTypePtr> ModelTypePtr vol_model_cast(const volatility::IVolatilityModel * pModel); template <class ModelTypeRef> ModelTypeRef vol_model_cast(volatility::IVolatilityModel & model); template <class ModelTypeRef> ModelTypeRef vol_model_cast(const volatility::IVolatilityModel & model); #define VOL_MODEL_PTR_CAST_IMPL(specifier, model, type) \\\\ template <> \\\\ inline specifier volatility::model * vol_model_cast(specifier volatility::IVolatilityModel * pModel) \\\\ { \\\\ if (TB_UNLIKELY(!pModel)) { \\\\ return nullptr; \\\\ } \\\\ \\\\ if (TB_UNLIKELY(pModel->GetVolatilityModelType() != type)) { \\\\ TBWARNING(\"Detected attempt to cast volatility model of type \" << pModel->GetVolatilityModelType() << \" to type \" << type); \\\\ throw volatility::VolatilityModelTypeMismatchException(pModel->GetVolatilityModelType(), type); \\\\ } \\\\ \\\\ return reinterpret_cast<specifier volatility::model*>(pModel); \\\\ } #define VOL_MODEL_REF_CAST_IMPL(specifier, model, type) \\\\ template <> \\\\ inline specifier volatility::model & vol_model_cast(specifier volatility::IVolatilityModel & rModel) \\\\ { \\\\ if (TB_UNLIKELY(rModel.GetVolatilityModelType() != type)) { \\\\ TBWARNING(\"Detected attempt to cast volatility model of type \" << rModel.GetVolatilityModelType() << \" to type \" << type); \\\\ throw volatility::VolatilityModelTypeMismatchException(rModel.GetVolatilityModelType(), type); \\\\ } \\\\ \\\\ return reinterpret_cast<specifier volatility::model&>(rModel); \\\\ } #define VOL_MODEL_CAST_IMPL(specifier, model, type) \\\\ VOL_MODEL_PTR_CAST_IMPL(specifier, model, type) \\\\ VOL_MODEL_REF_CAST_IMPL(specifier, model, type) VOL_MODEL_CAST_IMPL(const, ClampedCubicSpline, VolatilityModelCCS) VOL_MODEL_CAST_IMPL(, ClampedCubicSpline, VolatilityModelCCS) VOL_MODEL_CAST_IMPL(const, StochasticVolatilityInspired, VolatilityModelSVI) VOL_MODEL_CAST_IMPL(, StochasticVolatilityInspired, VolatilityModelSVI)<FIM_SUFFIX>VOL_MODEL_CAST_IMPL(, WingVolatilityModel, VolatilityModelWing) #undef VOL_MODEL_CAST_IMPL #undef VOL_MODEL_REF_CAST_IMPL #undef VOL_MODEL_PTR_CAST_IMPL<fim-suffix><fim-middle>VOL_MODEL_CAST_IMPL(const, WingVolatilityModel, VolatilityModelWing)'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds2[\"train\"].__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de84b2cc-0c95-48c0-8648-e2c0b0ead336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa775815eb4041dd9dd68baaa644358e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the dataset from the JSONL file\n",
    "mydataset = load_dataset('json', data_files='prompt_nosuffix_test.jsonl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "597ac4d9-38f4-4794-a7cd-3190c3230194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['content'],\n",
       "        num_rows: 2113\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135fac07-0bfc-4cd8-8fd5-cf0fca6ad760",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flashenv",
   "language": "python",
   "name": "flashenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

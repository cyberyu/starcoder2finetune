{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97e89599",
   "metadata": {},
   "source": [
    "# vLLM Remote Testing - Clean Setup\n",
    "\n",
    "This notebook tests vLLM queries via WebIDE backend from a remote Jupyter server on EC2.\n",
    "\n",
    "## Setup Requirements:\n",
    "1. Jupyter server running on EC2\n",
    "2. SSH tunnel active\n",
    "3. WebIDE running on EC2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30850648",
   "metadata": {},
   "source": [
    "## SIMPLIFIED Setup - No SSH Needed!\n",
    "\n",
    "**Since SSH authentication is problematic, let's use the simple approach:**\n",
    "\n",
    "### Step 1: Use This Notebook Locally\n",
    "- Just run this notebook in VS Code locally (no SSH tunnel needed)\n",
    "- It will connect directly to your WebIDE on EC2\n",
    "\n",
    "### Step 2: Make Sure WebIDE is Running\n",
    "- Your WebIDE should be running on: `http://10.230.0.178:3001`\n",
    "- That's it! No SSH, no tunnels, no complications.\n",
    "\n",
    "### Why This Works:\n",
    "- Tests the exact same `/api/vllm/completions` endpoint\n",
    "- Uses the same request format as your WebIDE frontend\n",
    "- Much simpler setup!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42136548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ SIMPLE APPROACH: Local Jupyter â†’ EC2 WebIDE\n",
      "ğŸŒ WebIDE URL: http://10.230.0.178:3001\n",
      "ğŸš€ Testing endpoint: http://10.230.0.178:3001/api/vllm/completions\n",
      "ğŸ“ No SSH tunnels, no complications!\n",
      "âœ… WebIDE is reachable! Status: 200\n"
     ]
    }
   ],
   "source": [
    "# SIMPLIFIED: Connect directly to WebIDE on EC2 (no SSH tunnel)\n",
    "import requests\n",
    "import json\n",
    "from typing import Dict, Any, List\n",
    "\n",
    "# Direct connection to your WebIDE on EC2\n",
    "BASE_URL = \"http://10.230.0.178:3001\"\n",
    "COMPLETIONS_ENDPOINT = f\"{BASE_URL}/api/vllm/completions\"\n",
    "MODELS_ENDPOINT = f\"{BASE_URL}/api/vllm/models\"\n",
    "\n",
    "HEADERS = {\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "print(\"ğŸ¯ SIMPLE APPROACH: Local Jupyter â†’ EC2 WebIDE\")\n",
    "print(f\"ğŸŒ WebIDE URL: {BASE_URL}\")\n",
    "print(f\"ğŸš€ Testing endpoint: {COMPLETIONS_ENDPOINT}\")\n",
    "print(\"ğŸ“ No SSH tunnels, no complications!\")\n",
    "\n",
    "# Test connection\n",
    "try:\n",
    "    response = requests.get(f\"{BASE_URL}\", timeout=10)\n",
    "    print(f\"âœ… WebIDE is reachable! Status: {response.status_code}\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Cannot reach WebIDE: {e}\")\n",
    "    print(\"ğŸ”§ Make sure WebIDE is running on EC2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "516741a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ Fetching available models...\n",
      "ğŸ” Checking models: http://10.230.0.178:3001/api/vllm/models\n",
      "âŒ Error: 500 Server Error: Internal Server Error for url: http://10.230.0.178:3001/api/vllm/models\n"
     ]
    }
   ],
   "source": [
    "# Check available models (using the working URL)\n",
    "import time\n",
    "\n",
    "def get_available_models() -> List[str]:\n",
    "    \"\"\"Get available models from WebIDE backend.\"\"\"\n",
    "    try:\n",
    "        print(f\"ğŸ” Checking models: {MODELS_ENDPOINT}\")\n",
    "        response = requests.get(MODELS_ENDPOINT, headers=HEADERS, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        models_data = response.json()\n",
    "        models = [model['id'] for model in models_data.get('data', [])]\n",
    "        \n",
    "        print(f\"âœ… Found {len(models)} models:\")\n",
    "        for i, model in enumerate(models, 1):\n",
    "            print(f\"  {i}. {model}\")\n",
    "        \n",
    "        return models\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error: {e}\")\n",
    "        return []\n",
    "\n",
    "# ENHANCED execution guard with timestamp to prevent any duplicates\n",
    "current_time = time.time()\n",
    "execution_key = f\"models_fetched_{current_time}\"\n",
    "\n",
    "# Check if we already executed this recently (within 5 seconds)\n",
    "if ('available_models' in globals() and \n",
    "    available_models and \n",
    "    hasattr(globals().get('_last_model_fetch', None), '__dict__') and\n",
    "    current_time - getattr(globals().get('_last_model_fetch', type('obj', (), {'time': 0})()), 'time', 0) < 5):\n",
    "    \n",
    "    print(f\"âœ… Using recently cached models: {available_models}\")\n",
    "    print(f\"   (Found {len(available_models)} models, cached {current_time - _last_model_fetch.time:.1f}s ago)\")\n",
    "    \n",
    "elif 'available_models' not in globals() or not available_models:\n",
    "    print(\"ğŸ”§ Fetching available models...\")\n",
    "    available_models = get_available_models()\n",
    "    # Mark when we last fetched\n",
    "    _last_model_fetch = type('obj', (), {'time': current_time})()\n",
    "    \n",
    "else:\n",
    "    print(f\"âœ… Using cached models: {available_models}\")\n",
    "    print(f\"   (Found {len(available_models)} models already loaded)\")\n",
    "    # Update timestamp even for existing cache\n",
    "    _last_model_fetch = type('obj', (), {'time': current_time})()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "294ff481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Testing Exact WebIDE Example ===\n",
      "Code: 'void AutoRefill::HandleDeleteRequest()\\nvoid AutoRefill::HandleModifyRequest(const StrategyModifier& modifier)'\n",
      "Cursor at position: 109\n",
      "\n",
      "ğŸš€ Testing vLLM completion...\n",
      "ğŸ“ Model: /data/starcoder2_7b_triple_Train_w8a8_optimal\n",
      "ğŸ“ Cursor position: 109\n",
      "ğŸ” Prompt preview: <fim_prefix>void AutoRefill::HandleDeleteRequest()\n",
      "void AutoRefill::HandleModifyRequest(const Strate...\n",
      "âœ… Success! Status: 200\n",
      "ğŸ¯ Generated 1 completion(s):\n",
      "\n",
      "Completion 1:\n",
      "'    TBDEBUG(\"HandleModifyRequest: \" << modifier);\n",
      "void AutoRefill::HandleValidateRequest(ValidationContext& context) const\n",
      "void AutoRefill::HandleStreamOpen(const StreamIdentifier& stream) { TBDEBUG(\"HandleStreamOpen: \" << stream); }\n",
      "void AutoRefill::HandleStreamStale(const StreamIdentifier& stream) { TBWARNING(\"HandleStreamStale: \" << stream); }\n",
      "void AutoRefill::HandleStreamFailed(const StreamIdentifier& stream) { TBERROR(\"HandleStreamFailed: \" << stream); }\n",
      "void AutoRefill::HandleSnapshotEnd(const'\n"
     ]
    }
   ],
   "source": [
    "# Test exact WebIDE vLLM query\n",
    "def test_vllm_completion(code: str, cursor_pos: int) -> Dict[str, Any]:\n",
    "    \"\"\"Test vLLM completion via WebIDE backend.\"\"\"\n",
    "    \n",
    "    # Create FIM prompt (same as WebIDE)\n",
    "    prefix = code[:cursor_pos]\n",
    "    suffix = code[cursor_pos:]\n",
    "    fim_prompt = f\"<fim_prefix>{prefix}<fim_suffix>{suffix}<fim_middle>\"\n",
    "    \n",
    "    # Use first available model\n",
    "    model = available_models[0] if available_models else \"default\"\n",
    "    \n",
    "    request_body = {\n",
    "        \"model\": model,\n",
    "        \"prompt\": fim_prompt,\n",
    "        \"echo\": False,\n",
    "        \"n\": 1,\n",
    "        \"max_tokens\": 128,\n",
    "        \"temperature\": 0.2,\n",
    "        \"top_p\": 0.95\n",
    "    }\n",
    "    \n",
    "    print(f\"ğŸš€ Testing vLLM completion...\")\n",
    "    print(f\"ğŸ“ Model: {model}\")\n",
    "    print(f\"ğŸ“ Cursor position: {cursor_pos}\")\n",
    "    print(f\"ğŸ” Prompt preview: {fim_prompt[:100]}...\")\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(\n",
    "            COMPLETIONS_ENDPOINT,\n",
    "            headers=HEADERS,\n",
    "            json=request_body,\n",
    "            timeout=30\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        result = response.json()\n",
    "        \n",
    "        print(f\"âœ… Success! Status: {response.status_code}\")\n",
    "        \n",
    "        choices = result.get('choices', [])\n",
    "        print(f\"ğŸ¯ Generated {len(choices)} completion(s):\")\n",
    "        \n",
    "        for i, choice in enumerate(choices, 1):\n",
    "            text = choice.get('text', '')\n",
    "            print(f\"\\nCompletion {i}:\")\n",
    "            print(f\"'{text}'\")\n",
    "        \n",
    "        return {\"success\": True, \"result\": result, \"request\": request_body}\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Request failed: {e}\")\n",
    "        return {\"success\": False, \"error\": str(e), \"request\": request_body}\n",
    "\n",
    "# Test with the exact console log example\n",
    "test_code = \"\"\"void AutoRefill::HandleDeleteRequest()\n",
    "void AutoRefill::HandleModifyRequest(const StrategyModifier& modifier)\"\"\"\n",
    "\n",
    "cursor_position = len(test_code)  # End of code\n",
    "\n",
    "print(\"=== Testing Exact WebIDE Example ===\")\n",
    "print(f\"Code: {repr(test_code)}\")\n",
    "print(f\"Cursor at position: {cursor_position}\\n\")\n",
    "\n",
    "result = test_vllm_completion(test_code, cursor_position)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5146138f",
   "metadata": {},
   "source": [
    "## Results Summary\n",
    "\n",
    "If the above test works, you have successfully:\n",
    "- âœ… Connected to WebIDE backend directly\n",
    "- âœ… Tested vLLM completion with exact WebIDE format\n",
    "- âœ… Verified the same request path as the frontend\n",
    "\n",
    "This setup allows you to test vLLM queries exactly as the WebIDE frontend does!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d734b1",
   "metadata": {},
   "source": [
    "## FIM Validation Results Summary\n",
    "\n",
    "The validation loop above tests your WebIDE's vLLM backend against real FIM test cases from the JSONL file.\n",
    "\n",
    "### What It Tests:\n",
    "- âœ… **Loads FIM tasks** from `multiline_fim_viewer_compatible.jsonl`\n",
    "- âœ… **Sends each task** to your WebIDE backend exactly like the frontend does\n",
    "- âœ… **Validates completions** against expected outputs\n",
    "- âœ… **Provides metrics** on success rate and quality\n",
    "\n",
    "### Key Metrics:\n",
    "- **Success Rate**: % of completions that generated valid output\n",
    "- **Similarity Score**: How close generated text is to expected (0-1)\n",
    "- **Performance Stats**: Average prefix/suffix lengths and response times\n",
    "\n",
    "### This Validates:\n",
    "1. **WebIDE Backend** is properly handling vLLM requests\n",
    "2. **vLLM Model** is generating reasonable completions\n",
    "3. **Request Format** matches exactly what your frontend sends\n",
    "4. **End-to-End Flow** from test cases â†’ WebIDE â†’ vLLM â†’ results\n",
    "\n",
    "Run the validation to see how well your setup performs on real FIM tasks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2fbed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¥ COMPREHENSIVE VALIDATION - Testing 10 FIM cases...\n",
      "ğŸ”¥ Simple test: 1 + 1 = 2\n",
      "ğŸ”¥ Available models: ['/data/starcoder2_7b_triple_Train_w8a8_optimal']\n",
      "ğŸ”¥ Variables found - proceeding with 10-case validation...\n",
      "ğŸ”¥ Loading from: /Users/shi.yu/Documents/tbricks_dataviewer/fim_singleline_dataset_deterministic.jsonl\n",
      "ğŸ”¥ File exists - loading test cases...\n",
      "ğŸ”¥ Loaded 10 test cases\n",
      "\n",
      "================================================================================\n",
      "ğŸ¯ STARTING 10-CASE FIM VALIDATION\n",
      "================================================================================\n",
      "\n",
      "ğŸ”¸ Test Case 1/10\n",
      "----------------------------------------\n",
      "ğŸ“ Prompt length: 85 chars\n",
      "? Prompt preview: <fim_prefix>void SetResponseTime( market_t m, const tbricks::<fim_suffix><fim_mi...\n",
      "ğŸ¯ Expected: Duration...\n",
      "âš¡ Response time: 2264.5ms\n",
      "âœ¨ Generated: Duration& t ) { m_response_times[m] = t; }Duration& t ) { m_...\n",
      "ğŸ”¥ âœ… EXACT MATCH FOUND!\n",
      "\n",
      "ğŸ”¸ Test Case 2/10\n",
      "----------------------------------------\n",
      "ğŸ“ Prompt length: 105 chars\n",
      "? Prompt preview: <fim_prefix>m_validationTable.InsertColumn(etf_static_data::strategy_parameters:...\n",
      "ğŸ¯ Expected: ETF_StaticDataOpenValidationApp...\n",
      "âš¡ Response time: 2261.2ms\n",
      "âœ¨ Generated: ETF_StaticDataName_LEFT_PARENTHESIS_ISO_RIGHT_PARENTHESIS_1_...\n",
      "ğŸ”¥ âŒ Different result\n",
      "\n",
      "ğŸ”¸ Test Case 3/10\n",
      "----------------------------------------\n",
      "ğŸ“ Prompt length: 71 chars\n",
      "? Prompt preview: <fim_prefix>void ContextOrderBookSubscription::<fim_suffix><fim_middle>...\n",
      "ğŸ¯ Expected: Recalculate...\n",
      "âš¡ Response time: 2263.2ms\n",
      "âœ¨ Generated: HandleStreamFailed(const StreamIdentifier & stream)\n",
      "void Con...\n",
      "ğŸ”¥ âŒ Different result\n",
      "\n",
      "ğŸ”¸ Test Case 4/10\n",
      "----------------------------------------\n",
      "ğŸ“ Prompt length: 106 chars\n",
      "? Prompt preview: <fim_prefix>InstrumentParametersStreamMock(IHandler & handler) : m_streamid(Uuid...\n",
      "ğŸ¯ Expected: Create...\n",
      "âš¡ Response time: 2245.4ms\n",
      "âœ¨ Generated: Create()) { }Create), m_handler(handler) { } InstrumentParam...\n",
      "ğŸ”¥ âœ… EXACT MATCH FOUND!\n",
      "\n",
      "ğŸ”¸ Test Case 5/10\n",
      "----------------------------------------\n",
      "ğŸ“ Prompt length: 97 chars\n",
      "? Prompt preview: <fim_prefix>CalculatedInstrumentValues::Stream::Options VolatilityOrder::<fim_su...\n",
      "ğŸ¯ Expected: CalculatedStreamOptions...\n",
      "âš¡ Response time: 2249.2ms\n",
      "âœ¨ Generated: GetVolatilityStreamOptionsForCurrentMaturityGroupAndStrikeIn...\n",
      "ğŸ”¥ âŒ Different result\n",
      "\n",
      "ğŸ”¸ Test Case 6/10\n",
      "----------------------------------------\n",
      "ğŸ“ Prompt length: 126 chars\n",
      "? Prompt preview: <fim_prefix>int row = m_tradeView.GetTable().FindRow(distribute_trades_advanced:...\n",
      "ğŸ¯ Expected: TradeIdentifier...\n",
      "âš¡ Response time: 2286.6ms\n",
      "âœ¨ Generated: HTT_TradeStateDescriptionParameter\", htt::trade_state::HTT_T...\n",
      "ğŸ”¥ âŒ Different result\n",
      "\n",
      "ğŸ”¸ Test Case 7/10\n",
      "----------------------------------------\n",
      "ğŸ“ Prompt length: 76 chars\n",
      "? Prompt preview: <fim_prefix>tbricks::Volume SimpleSpreaderSkeleton::<fim_suffix><fim_middle>...\n",
      "ğŸ¯ Expected: GetHedgeVWAPVolume...\n",
      "âš¡ Response time: 2246.5ms\n",
      "âœ¨ Generated: GetHedgeVolumeToQuoteRatioForModeAndPriceLevelAndSideAndBait...\n",
      "ğŸ”¥ âŒ Different result\n",
      "\n",
      "ğŸ”¸ Test Case 8/10\n",
      "----------------------------------------\n",
      "ğŸ“ Prompt length: 59 chars\n",
      "? Prompt preview: <fim_prefix>case ProductGroupType::<fim_suffix><fim_middle>...\n",
      "ğŸ¯ Expected: CURRENT...\n",
      "âš¡ Response time: 2271.0ms\n",
      "âœ¨ Generated: EXCHANGE_TRADED_GROUP_TYPE_FUTURES_AND_OPTIONS_GROUP_TYPE_CA...\n",
      "ğŸ”¥ âŒ Different result\n",
      "\n",
      "ğŸ”¸ Test Case 9/10\n",
      "----------------------------------------\n",
      "ğŸ“ Prompt length: 56 chars\n",
      "? Prompt preview: <fim_prefix>void FXAlgoOptions::<fim_suffix><fim_middle>...\n",
      "ğŸ¯ Expected: Clear...\n",
      "âš¡ Response time: 2249.8ms\n",
      "âœ¨ Generated: HandleStreamFailed(const StreamIdentifier& stream)\n",
      "void FXAl...\n",
      "ğŸ”¥ âŒ Different result\n",
      "\n",
      "ğŸ”¸ Test Case 10/10\n",
      "----------------------------------------\n",
      "ğŸ“ Prompt length: 89 chars\n",
      "? Prompt preview: <fim_prefix>void ServiceUnavailable( const std::vector< tbricks::<fim_suffix><fi...\n",
      "ğŸ¯ Expected: OrderIdentifier...\n",
      "âš¡ Response time: 2272.3ms\n",
      "âœ¨ Generated: Identifier >& ids, const tbricks::String& reason, const tbri...\n",
      "ğŸ”¥ âŒ Different result\n",
      "\n",
      "================================================================================\n",
      "ğŸ“Š VALIDATION SUMMARY\n",
      "================================================================================\n",
      "âœ… Successful tests: 2/10\n",
      "âŒ Failed tests: 8/10\n",
      "ğŸ“ˆ Success rate: 20.0%\n",
      "âš¡ Average response time: 11304.9ms\n",
      "ğŸ¯ Model used: /data/starcoder2_7b_triple_Train_w8a8_optimal\n",
      "ğŸŒ Endpoint: http://10.230.0.178:3001/api/vllm/completions\n",
      "? LOW SUCCESS RATE - Check WebIDE and vLLM configuration\n",
      "\n",
      "ğŸ”¥ 10-CASE VALIDATION COMPLETED!\n"
     ]
    }
   ],
   "source": [
    "# FIM VALIDATION - 1000 Test Cases (Simplified)\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "\n",
    "print(\"ğŸ¯ Running FIM validation on 1000 test cases...\")\n",
    "\n",
    "# Check prerequisites\n",
    "if 'available_models' not in globals() or not available_models:\n",
    "    print(\"âŒ Run previous cells first to initialize models\")\n",
    "    exit()\n",
    "\n",
    "# Load test cases\n",
    "jsonl_path = \"/Users/shi.yu/Documents/tbricks_dataviewer/fim_singleline_dataset_deterministic.jsonl\"\n",
    "if not os.path.exists(jsonl_path):\n",
    "    print(f\"âŒ Test file not found: {jsonl_path}\")\n",
    "    exit()\n",
    "\n",
    "# Load and parse test cases\n",
    "test_cases = []\n",
    "with open(jsonl_path, 'r', encoding='utf-8', errors='replace') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i >= 1000:  # Load up to 1000 cases\n",
    "            break\n",
    "        line = line.strip()\n",
    "        if line:\n",
    "            try:\n",
    "                test_cases.append(json.loads(line))\n",
    "            except:\n",
    "                continue  # Skip malformed lines silently\n",
    "\n",
    "print(f\"âœ… Loaded {len(test_cases)} test cases\")\n",
    "\n",
    "# Run validation\n",
    "successful_tests = 0\n",
    "failed_tests = 0\n",
    "total_response_time = 0\n",
    "results = []\n",
    "\n",
    "for i, test_case in enumerate(test_cases, 1):\n",
    "    # Parse FIM content\n",
    "    content = test_case.get('content', '')\n",
    "    if '<fim_middle>' not in content:\n",
    "        failed_tests += 1\n",
    "        continue\n",
    "        \n",
    "    parts = content.split('<fim_middle>')\n",
    "    prompt = parts[0] + '<fim_middle>'\n",
    "    expected = parts[1] if len(parts) > 1 else \"\"\n",
    "    \n",
    "    # Make API call\n",
    "    try:\n",
    "        request_body = {\n",
    "            \"model\": available_models[0],\n",
    "            \"prompt\": prompt,\n",
    "            \"max_tokens\": 100,\n",
    "            \"temperature\": 0.3,\n",
    "            \"echo\": False\n",
    "        }\n",
    "        \n",
    "        start_time = time.time()\n",
    "        response = requests.post(COMPLETIONS_ENDPOINT, headers=HEADERS, json=request_body, timeout=20)\n",
    "        response_time = (time.time() - start_time) * 1000\n",
    "        \n",
    "        response.raise_for_status()\n",
    "        result = response.json()\n",
    "        choices = result.get('choices', [])\n",
    "        \n",
    "        if choices:\n",
    "            generated = choices[0].get('text', '').strip()\n",
    "            total_response_time += response_time\n",
    "            \n",
    "            # Check match quality\n",
    "            if expected and expected.lower().strip() in generated.lower():\n",
    "                match_type = \"âœ… EXACT\"\n",
    "                successful_tests += 1\n",
    "            elif expected and any(word in generated.lower() for word in expected.lower().split()[:3]):\n",
    "                match_type = \"âœ… PARTIAL\"\n",
    "                successful_tests += 1\n",
    "            else:\n",
    "                match_type = \"âŒ NO MATCH\"\n",
    "                failed_tests += 1\n",
    "                \n",
    "            # Store compact result (only for failed cases or every 100th)\n",
    "            if match_type == \"âŒ NO MATCH\" or i % 100 == 0:\n",
    "                results.append(f\"Test {i}: {match_type} ({response_time:.0f}ms)\")\n",
    "        else:\n",
    "            results.append(f\"Test {i}: âŒ NO OUTPUT\")\n",
    "            failed_tests += 1\n",
    "            \n",
    "    except Exception as e:\n",
    "        if i % 100 == 0:  # Only log errors for milestone tests\n",
    "            results.append(f\"Test {i}: âŒ ERROR - {str(e)[:50]}\")\n",
    "        failed_tests += 1\n",
    "    \n",
    "    # Progress indicator every 50 tests\n",
    "    if i % 50 == 0 or i == len(test_cases):\n",
    "        success_rate = (successful_tests / i) * 100\n",
    "        print(f\"Progress: {i}/{len(test_cases)} | Success: {success_rate:.1f}% | Avg: {(total_response_time/max(successful_tests,1)):.0f}ms\")\n",
    "    \n",
    "    # Rate limiting - shorter delay for large batch\n",
    "    time.sleep(0.1)\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“Š VALIDATION RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"âœ… Success: {successful_tests}/{len(test_cases)} ({(successful_tests/len(test_cases))*100:.1f}%)\")\n",
    "print(f\"âŒ Failed: {failed_tests}/{len(test_cases)}\")\n",
    "\n",
    "if successful_tests > 0:\n",
    "    avg_time = total_response_time / successful_tests\n",
    "    print(f\"âš¡ Avg response: {avg_time:.0f}ms\")\n",
    "    print(f\"â±ï¸ Total time: {(total_response_time/1000):.1f}s\")\n",
    "\n",
    "print(f\"ğŸ¤– Model: {available_models[0]}\")\n",
    "\n",
    "# Overall assessment\n",
    "success_rate = (successful_tests / len(test_cases)) * 100\n",
    "if success_rate >= 70:\n",
    "    print(\"ğŸ‰ EXCELLENT - WebIDE pipeline working well!\")\n",
    "elif success_rate >= 50:\n",
    "    print(\"ğŸ‘ GOOD - Backend functional\")\n",
    "elif success_rate >= 30:\n",
    "    print(\"âš ï¸ PARTIAL - Some issues detected\")\n",
    "else:\n",
    "    print(\"ğŸš¨ POOR - Check configuration\")\n",
    "\n",
    "# Show sample results\n",
    "show_details = False  # Set to True to see milestone and failed test results\n",
    "if show_details and results:\n",
    "    print(f\"\\nSample Results ({len(results)} shown):\")\n",
    "    for result in results[-10:]:  # Show last 10 results\n",
    "        print(f\"  {result}\")\n",
    "\n",
    "print(\"âœ… Validation completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cf54e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ†˜ EMERGENCY TEST - Can you see this output?\n",
      "ğŸ†˜ If yes, the kernel is working but the previous cell was stuck\n",
      "ğŸ†˜ Current time: 2025-10-01 23:10:22.490316\n",
      "ğŸ†˜ Python version: 3.13.5 | packaged by Anaconda, Inc. | (main, Jun 12 2025, 11:23:37) [Clang 14.0.6 ]\n",
      "ğŸ†˜ Simple math test: 2 + 2 = 4\n",
      "ğŸ†˜ Globals check:\n",
      "ğŸ†˜ available_models exists: False\n",
      "ğŸ†˜ âŒ Need to re-run previous cells after kernel restart\n",
      "ğŸ†˜ END OF EMERGENCY TEST\n"
     ]
    }
   ],
   "source": [
    "# EMERGENCY TEST - New cell to check if kernel is working\n",
    "print(\"ğŸ†˜ EMERGENCY TEST - Can you see this output?\")\n",
    "print(\"ğŸ†˜ If yes, the kernel is working but the previous cell was stuck\")\n",
    "print(\"ğŸ†˜ Current time:\", __import__('datetime').datetime.now())\n",
    "\n",
    "# Test very basic functionality\n",
    "import sys\n",
    "print(f\"ğŸ†˜ Python version: {sys.version}\")\n",
    "print(\"ğŸ†˜ Simple math test: 2 + 2 =\", 2 + 2)\n",
    "\n",
    "# Check if we can access previous variables\n",
    "print(\"ğŸ†˜ Globals check:\")\n",
    "available_models_exists = 'available_models' in globals()\n",
    "print(f\"ğŸ†˜ available_models exists: {available_models_exists}\")\n",
    "\n",
    "if available_models_exists:\n",
    "    print(f\"ğŸ†˜ available_models value: {available_models}\")\n",
    "    print(\"ğŸ†˜ âœ… Previous cells' variables are accessible!\")\n",
    "else:\n",
    "    print(\"ğŸ†˜ âŒ Need to re-run previous cells after kernel restart\")\n",
    "\n",
    "print(\"ğŸ†˜ END OF EMERGENCY TEST\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

# C++ FIM Dataset Pipeline

This folder contains the complete C++ Fill-in-the-Middle (FIM) dataset generation and filtering pipeline with quality score integration.

## Core Pipeline Scripts

### Main Pipeline Runner
- **`run_pipeline_with_preprocessor_fix.py`** - Main pipeline orchestrator with preprocessor structure validation

### Phase Scripts
- **`extract_nextline_pairs.py`** - Phase 0: Extract FIM pairs from C++ codebase
- **`filter_quality_fim_tasks.py`** - Phase 1: Context quality filtering 
- **`apply_middle_content_filter.py`** - Phase 2: Middle content quality filtering
- **`apply_phase3b_improved_filter.py`** - Phase 3B: Adaptive length-based filtering

### Quality Score Integration
- **`calculate_comprehensive_quality_scores.py`** - Calculate comprehensive quality scores for all tasks

### Validation & Analysis
- **`validate_quality_scores.py`** - Validate quality score integration
- **`quality_pipeline_summary.py`** - Generate pipeline execution summary

### Visualization
- **`fimdatasetViewer.html`** - Interactive HTML viewer for inspecting FIM dataset with quality scores

## Documentation
- **`PIPELINE_SUMMARY.md`** - Comprehensive pipeline documentation with quality metrics
- **`PREPROCESSOR_FIX_SUMMARY.md`** - Documentation of preprocessor structure validation fix

## Usage

### Run Complete Pipeline
```bash
# Run with existing base dataset
python run_pipeline_with_preprocessor_fix.py

# Regenerate base dataset with preprocessor fixes
python run_pipeline_with_preprocessor_fix.py --regenerate

# Run with verbose output
python run_pipeline_with_preprocessor_fix.py --verbose
```

### Add Quality Scores to Existing Dataset
```bash
python calculate_comprehensive_quality_scores.py
```

### Validate Results
```bash
python validate_quality_scores.py
python quality_pipeline_summary.py
```

### View Dataset
Open `fimdatasetViewer.html` in a web browser and load any JSONL file to inspect tasks with quality scores.

## Pipeline Flow

1. **Phase 0** (Optional): Extract FIM pairs from C++ source code with preprocessor validation
2. **Phase 1**: Filter based on prefix context quality (acceptance: ~29%)
3. **Phase 2**: Filter based on middle content patterns (acceptance: ~89%)
4. **Phase 3B**: Adaptive length-based filtering (acceptance: ~75%)
5. **Quality Integration**: Calculate comprehensive quality scores for all tasks

## Output Files

- `prompts_codebricks_autogenerated_underscore.jsonl` - Phase 0 output (raw extraction)
- `prompts_codebricks_filtered_improved.jsonl` - Phase 1 output (context quality filtered)
- `prompts_codebricks_filtered_middle_quality.jsonl` - Phase 2 output (middle content filtered)
- `prompts_codebricks_filtered_phase3b_improved.jsonl` - Phase 3B output (final filtered dataset)
- `prompts_codebricks_final_with_quality_scores.jsonl` - Final dataset with comprehensive quality scores

## Quality Scores Structure

Each task includes:
```json
{
  "content": "<fim_prefix>...code...<fim_suffix><fim_middle>...completion...",
  "quality_scores": {
    "phase1_context_quality": 0.850,
    "phase2_middle_quality": 0.900,
    "phase3_length_quality": 0.750,
    "composite_quality": 0.833
  },
  "quality_metrics": {
    "prefix_length": 245,
    "middle_length": 87,
    "ratio": 0.355
  },
  "quality_tier": "high"
}
```

## Requirements

- Python 3.7+
- Access to C++ source code in `../code/` directory (for Phase 0)
- Sufficient disk space for intermediate files

## Key Features

- ✅ Preprocessor structure validation (prevents orphaned `#else` patterns)
- ✅ Multi-phase quality filtering with adaptive thresholds
- ✅ Comprehensive quality score calculation
- ✅ Interactive dataset viewer with search and quality filtering
- ✅ Detailed validation and analysis tools
- ✅ Memory-efficient processing for large datasets
